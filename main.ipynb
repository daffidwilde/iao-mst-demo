{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wildeh\\src\\private-pgm\\src\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from disjoint_set import DisjointSet\n",
    "from mbi import FactoredInference, Dataset, Domain\n",
    "from scipy import sparse\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from cdp2adp import cdp_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Taken from https://github.com/ryan112358/private-pgm/blob/master/mechanisms/mst.py\n",
    "\n",
    "This is a generalization of the winning mechanism from the \n",
    "2018 NIST Differential Privacy Synthetic Data Competition.\n",
    "\n",
    "Unlike the original implementation, this one can work for any discrete dataset,\n",
    "and does not rely on public provisional data for measurement selection.  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def MST(data, epsilon, delta):\n",
    "    rho = cdp_rho(epsilon, delta)\n",
    "    sigma = np.sqrt(3 / (2 * rho))\n",
    "    cliques = [(col,) for col in data.domain]\n",
    "    log1 = measure(data, cliques, sigma)\n",
    "    data, log1, undo_compress_fn = compress_domain(data, log1)\n",
    "    cliques = select(data, rho / 3.0, log1)\n",
    "    log2 = measure(data, cliques, sigma)\n",
    "    engine = FactoredInference(data.domain, iters=5000)\n",
    "    est = engine.estimate(log1 + log2)\n",
    "    synth = est.synthetic_data()\n",
    "    return undo_compress_fn(synth)\n",
    "\n",
    "\n",
    "def measure(data, cliques, sigma, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(cliques))\n",
    "    weights = np.array(weights) / np.linalg.norm(weights)\n",
    "    measurements = []\n",
    "    for proj, wgt in zip(cliques, weights):\n",
    "        x = data.project(proj).datavector()\n",
    "        y = x + np.random.normal(loc=0, scale=sigma / wgt, size=x.size)\n",
    "        Q = sparse.eye(x.size)\n",
    "        measurements.append((Q, y, sigma / wgt, proj))\n",
    "    return measurements\n",
    "\n",
    "\n",
    "def compress_domain(data, measurements):\n",
    "    supports = {}\n",
    "    new_measurements = []\n",
    "    for Q, y, sigma, proj in measurements:\n",
    "        col = proj[0]\n",
    "        sup = y >= 3 * sigma\n",
    "        supports[col] = sup\n",
    "        if supports[col].sum() == y.size:\n",
    "            new_measurements.append((Q, y, sigma, proj))\n",
    "        else:  # need to re-express measurement over the new domain\n",
    "            y2 = np.append(y[sup], y[~sup].sum())\n",
    "            I2 = np.ones(y2.size)\n",
    "            I2[-1] = 1.0 / np.sqrt(y.size - y2.size + 1.0)\n",
    "            y2[-1] /= np.sqrt(y.size - y2.size + 1.0)\n",
    "            I2 = sparse.diags(I2)\n",
    "            new_measurements.append((I2, y2, sigma, proj))\n",
    "    undo_compress_fn = lambda data: reverse_data(data, supports)\n",
    "    return transform_data(data, supports), new_measurements, undo_compress_fn\n",
    "\n",
    "\n",
    "def exponential_mechanism(q, eps, sensitivity, prng=np.random, monotonic=False):\n",
    "    coef = 1.0 if monotonic else 0.5\n",
    "    scores = coef * eps / sensitivity * q\n",
    "    probas = np.exp(scores - logsumexp(scores))\n",
    "    return prng.choice(q.size, p=probas)\n",
    "\n",
    "\n",
    "def select(data, rho, measurement_log, cliques=[]):\n",
    "    engine = FactoredInference(data.domain, iters=1000)\n",
    "    est = engine.estimate(measurement_log)\n",
    "\n",
    "    weights = {}\n",
    "    candidates = list(itertools.combinations(data.domain.attrs, 2))\n",
    "    for a, b in candidates:\n",
    "        xhat = est.project([a, b]).datavector()\n",
    "        x = data.project([a, b]).datavector()\n",
    "        weights[a, b] = np.linalg.norm(x - xhat, 1)\n",
    "\n",
    "    T = nx.Graph()\n",
    "    T.add_nodes_from(data.domain.attrs)\n",
    "    ds = DisjointSet()\n",
    "\n",
    "    for e in cliques:\n",
    "        T.add_edge(*e)\n",
    "        ds.union(*e)\n",
    "\n",
    "    r = len(list(nx.connected_components(T)))\n",
    "    epsilon = np.sqrt(8 * rho / (r - 1))\n",
    "    for i in range(r - 1):\n",
    "        candidates = [e for e in candidates if not ds.connected(*e)]\n",
    "        wgts = np.array([weights[e] for e in candidates])\n",
    "        idx = exponential_mechanism(wgts, epsilon, sensitivity=1.0)\n",
    "        e = candidates[idx]\n",
    "        T.add_edge(*e)\n",
    "        ds.union(*e)\n",
    "\n",
    "    return list(T.edges)\n",
    "\n",
    "\n",
    "def transform_data(data, supports):\n",
    "    df = data.df.copy()\n",
    "    newdom = {}\n",
    "    for col in data.domain:\n",
    "        support = supports[col]\n",
    "        size = support.sum()\n",
    "        newdom[col] = int(size)\n",
    "        if size < support.size:\n",
    "            newdom[col] += 1\n",
    "        mapping = {}\n",
    "        idx = 0\n",
    "        for i in range(support.size):\n",
    "            mapping[i] = size\n",
    "            if support[i]:\n",
    "                mapping[i] = idx\n",
    "                idx += 1\n",
    "        assert idx == size\n",
    "        df[col] = df[col].map(mapping)\n",
    "    newdom = Domain.fromdict(newdom)\n",
    "    return Dataset(df, newdom)\n",
    "\n",
    "\n",
    "def reverse_data(data, supports):\n",
    "    df = data.df.copy()\n",
    "    newdom = {}\n",
    "    for col in data.domain:\n",
    "        support = supports[col]\n",
    "        mx = support.sum()\n",
    "        newdom[col] = int(support.size)\n",
    "        idx, extra = np.where(support)[0], np.where(~support)[0]\n",
    "        mask = df[col] == mx\n",
    "        if extra.size == 0:\n",
    "            pass\n",
    "        else:\n",
    "            df.loc[mask, col] = np.random.choice(extra, mask.sum())\n",
    "        df.loc[~mask, col] = idx[df.loc[~mask, col]]\n",
    "    newdom = Domain.fromdict(newdom)\n",
    "    return Dataset(df, newdom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    \"\"\"Use an ordinal encoder to convert categorical data.\"\"\"\n",
    "\n",
    "    encoder = OrdinalEncoder().fit(data)\n",
    "    data = pd.DataFrame(\n",
    "        encoder.transform(data).astype(int), columns=data.columns\n",
    "    )\n",
    "\n",
    "    return data, encoder\n",
    "\n",
    "\n",
    "def load_data(path, skip=True):\n",
    "    \"\"\"Read in and prepare the data for synthesis.\"\"\"\n",
    "\n",
    "    if skip is True:\n",
    "        data = pd.read_csv(path, skiprows=1, header=False)\n",
    "    \n",
    "    data = pd.read_csv(path, skiprows=1).drop(\"Person ID\", axis=1)\n",
    "    data, encoder = encode_data(data)\n",
    "\n",
    "    return data, encoder\n",
    "    \n",
    "\n",
    "def decode_data(data, encoder):\n",
    "    \"\"\"Decode the data so it is interpretable.\"\"\"\n",
    "\n",
    "    return pd.DataFrame(encoder.inverse_transform(data), columns=data.columns)\n",
    "\n",
    "\n",
    "def get_sparse_column_pair(data):\n",
    "    \"\"\"Get the column pair with the lowest two-way marginal count.\"\"\"\n",
    "\n",
    "    pair = None\n",
    "    min_cell_count = np.inf\n",
    "    for a, b in itertools.combinations(data.columns, r=2):\n",
    "        count = data.groupby([a, b]).size().min()\n",
    "        if count < min_cell_count:\n",
    "            min_cell_count = count\n",
    "            pair = [a, b]\n",
    "\n",
    "    return pair\n",
    "\n",
    "\n",
    "def calculate_marginal_table(data, by, encoder=None):\n",
    "    \"\"\"Get a marginal table for a column or set thereof.\"\"\"\n",
    "\n",
    "    if encoder is not None:\n",
    "        data = data.pipe(decode_data, encoder)\n",
    "\n",
    "    table = data.groupby(by).size().rename(\"count\").reset_index()\n",
    "\n",
    "    if not isinstance(by, str) and len(by) > 1:\n",
    "        table = table.pivot(*by, \"count\")\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Person ID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data, encoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m a, b \u001b[38;5;241m=\u001b[39m pair \u001b[38;5;241m=\u001b[39m get_sparse_column_pair(data)\n\u001b[0;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(path):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\"Read in and prepare the data for synthesis.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPerson ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     data, encoder \u001b[38;5;241m=\u001b[39m encode_data(data)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, encoder\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pgm-dev\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pgm-dev\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pgm-dev\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pgm-dev\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pgm-dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Person ID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data, encoder = load_data(\"main.csv\")\n",
    "a, b = pair = get_sparse_column_pair(data)\n",
    "\n",
    "np.random.seed(0)\n",
    "epsilon, delta = 1, 10 ** -np.ceil(np.log10(len(data)))\n",
    "dataset = Dataset(data, Domain.fromdict(data.nunique().to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = cdp_rho(epsilon, delta)\n",
    "sigma = np.sqrt(3 / (2 * rho))\n",
    "cliques = [(col,) for col in dataset.domain]\n",
    "log1 = measure(dataset, cliques, sigma)\n",
    "dataset, log1, undo_compress_fn = compress_domain(dataset, log1)\n",
    "\n",
    "cliques = select(dataset, rho / 3.0, log1, cliques=[tuple(pair)])\n",
    "log2 = measure(dataset, cliques, sigma)\n",
    "\n",
    "engine = FactoredInference(dataset.domain, iters=5000)\n",
    "est = engine.estimate(log1 + log2)\n",
    "synth = est.synthetic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pipe(decode_data, encoder).sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth.df.pipe(decode_data, encoder).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_one_way(log1, col):\n",
    "    \"\"\"Get the noisy marginal table for a column.\"\"\"\n",
    "\n",
    "    noisy = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"noisy_count\": next(\n",
    "                    counts for _, counts, _, clique in log1 if clique == (col,)\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        .rename_axis(index=col)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return noisy\n",
    "\n",
    "\n",
    "def compare_one_ways(data, log1, synth, col):\n",
    "    \"\"\"Get a table comparing all the various one-way tables.\"\"\"\n",
    "\n",
    "    original = data.pipe(calculate_marginal_table, col).rename(\n",
    "        {\"count\": \"observed_count\"}, axis=1\n",
    "    )\n",
    "    noisy = get_noisy_one_way(log1, col)\n",
    "    synthetic = synth.df.pipe(calculate_marginal_table, col).rename(\n",
    "        {\"count\": \"synthetic_count\"}, axis=1\n",
    "    )\n",
    "\n",
    "    comparison = (\n",
    "        original.merge(noisy, on=col).merge(synthetic, on=col).set_index(col)\n",
    "    )\n",
    "    comparison.index += 1\n",
    "\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_one_ways(data, log1, synth, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_one_ways(data, log1, synth, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-way marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_two_way(log2, pair, domain):\n",
    "    \"\"\"Get the noisy marginal table for a pair of columns.\"\"\"\n",
    "\n",
    "    a, b = pair\n",
    "    shape = domain.project(pair).shape\n",
    "\n",
    "    noisy = pd.DataFrame(\n",
    "        next(\n",
    "            counts for _, counts, _, clique in log2 if clique == tuple(pair)\n",
    "        ).reshape(shape)\n",
    "    ).rename_axis(index=a, columns=b)\n",
    "\n",
    "    noisy.index += 1\n",
    "    noisy.columns += 1\n",
    "    \n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_marginal_table(data, pair, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_noisy_two_way(log2, pair, dataset.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_marginal_table(synth.df, pair, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "pgm-dev",
   "language": "python",
   "name": "pgm-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
